{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.sparse import csr_matrix\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch train and test datasets\n",
    "train_data = fetch_20newsgroups(subset='train')\n",
    "news_group_train_y = train_data['target']\n",
    "test_data = fetch_20newsgroups(subset='test')\n",
    "news_group_test_y = test_data['target']\n",
    "# convert into unigram matrix\n",
    "vectorizer = TfidfVectorizer()\n",
    "news_group_train_X = vectorizer.fit_transform(train_data['data'])\n",
    "news_group_test_X = vectorizer.transform(test_data['data'])\n",
    "# convert into a sparse matrix\n",
    "news_group_train_X = csr_matrix(news_group_train_X)\n",
    "news_group_test_X = csr_matrix(news_group_test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I run Logistic Regression on 20NG since it works better than Decision Trees. Using Chi squared works better than Mutual Information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chi-squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_chi2, _ = chi2(news_group_train_X, news_group_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 Features with best Chi-squared score\n[ 74944 103273  55328  53491 107529  39924  92868  32556  92893  61742\n  95455  27442  74953  34726  86963 126615  94323  44222  73126 121840\n  48395  79831  32754 109035  37820 106447  34048 129693 109067  89396\n  38493  55307  58076 108726  99267 122997  32390 113763  67296  47664\n 124478  43969  43710  68628  39601  34137  27576  43135 115062  89005\n  88240 101947  72234  40422  68541 105791  46777 105760 103588  68696\n  34341  48665  30431 110966  54240  77295  56466  34842  62688 103554\n  75081  52533  68620  89612 123603  27366 105785 106243  65577  94343\n  74917  58306  94342  12661  59910 101960  49463  46846  62410  94862\n  51588  95989  54590 101944 124573  69448  93536  68617 106869 107159\n  46509  38662  49047  27739  30128  30090 117015  40286  30827  94021\n 105696  29114  74753  93400 125155  35760 125671  37469 117029 105155\n  86099  69411  42390  49717  67773  83898 127115  98213  32046  33306\n  33199  39583  39596  60724 108764  94329  75018  29279  55489  39705\n  71678 124239 106184  90278  83685  72367  28856  58063  83638  27237\n  29400  88206  62784  39603  30101  69935  30105  43699  29108  37955\n  94037  60150  65675  31954  90168  59833  76249  78586  83865  29403\n  60915 113757  52476  39415  69907  31767  87121  29401  84462  48421\n  72154 124425 105492 104576  43230 117020  58487  63638  37780 104409\n 109061  60892  59626  72325  68693  33301  51591 124434  40446  68692]\n"
     ]
    }
   ],
   "source": [
    "print(\"200 Features with best Chi-squared score\")\n",
    "indices = np.argsort(nn_chi2)[-200:]\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = {}\n",
    "for k, v in vectorizer.vocabulary_.items():\n",
    "    vocabulary[v] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lciii rsa files expo sin circuit penguins behanna pens hamburg prb allan lcs br newton xlib play cview kmr4 vlb doctor mathew benedikt sox card sgi bmw zoo spacecraft offer cdt file games soldiers rangers waco beauchaine teams ini disease wings cubs cryptography islanders christianity bobbe alomar cpr tiff objective nsmca rider kent clinton isa security detroit secret rutgers israelis bontchev dos aurora stratus faith lunar forsale braves helmet rushdie lebanese espn islamic okcforum weapons algorithm secure server ico playoffs lc gay playoff 3d government riding duo devils he polygon encrypted privacy fbi ride wiretap jake phillies islam shipping shuttle des centris drive amanda athos atf turkey clayton ax pitching season arabs launch pgp wpd bus x11r5 caltech turks schneider nasa jaeger controller dyer intercon motorcycle xterm quadra batf bikes bible christ christian gtoal solntze players leafs argic firearms church kaldis widget serdar orbit morality keys apple game moon alaska armenia nsa henry christians atheism jews atheists crypto arab cars pitt graphics ide baseball optilink gordon livesey mac motif armenians guns team escrow chip jesus banks nhl armenian msg dod keith window scsi sandvik cramer turkish geb hockey car sale space gun god key israeli bike encryption windows clipper israel \n"
     ]
    }
   ],
   "source": [
    "indices = np.argsort(nn_chi2)[-200:]\n",
    "str = \"\"\n",
    "for i in range(200):\n",
    "    #print(train_data.target_names[i])\n",
    "    str += vocabulary[indices[i]] + \" \"\n",
    "print(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_news_group_train_X = news_group_train_X[:, indices]\n",
    "reduced_news_group_test_X = news_group_test_X[:, indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.6 s, sys: 25.3 s, total: 35.9 s\nWall time: 25.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "nn_clf = LogisticRegression(penalty='l2', n_jobs=-1, solver='sag')\n",
    "nn_clf.fit(reduced_news_group_train_X, news_group_train_y.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy score:  0.6741205586\nTest Accuracy score:  0.6107275624\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Accuracy score: \", nn_clf.score(reduced_news_group_train_X, news_group_train_y))\n",
    "print(\"Test Accuracy score: \", nn_clf.score(reduced_news_group_test_X, news_group_test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mutual Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_mutual_info = mutual_info_classif(news_group_train_X, news_group_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 Features with best Mutual Information score\n[ 63246  64200  96047   6475 114882  32988 128022  59195  28621   8266\n  76211  76715   4605  48753  78784  76683  52641  99755  55011  85032\n  34523  48450  75390 114688 124640  90763  91190  38019 108809 114692\n  59860  32976  76377  28421 119781  86839  94725  86914  32651   2336\n 112031 124061 128026  74675  98356  59686 104361 110355  81998  62696\n  78955 112674  32517  55411  96064  89377 113279  31414  43740 110697\n  68857 107539  47139  41614 125017  90946 119714 108821 119740  99822\n  32596 115663  59590 101990 104494  26605  86493 120941  94362 119701\n 114428 111533 123196 104830  79371  37219  55525 117211  80005 124031\n  83836 114800  63333  62821  68003 125053 105818  32422 124198  84681\n  79055 121265 123422  28615 107022  52907  88034 114625  86864 119737\n 123759  27721 101034  59779  42876 114520  61546 123796  62410 115133\n 114494  32491  27618 114508  92923  47982  48448 114418 114696  90686\n  58830  89919 119451 124055 123575  64186 124026  83706 124147  73201\n 128420  48546  71079 108799  75901  90774 124332  87626  80638  62123\n 108558  28601  48351  25399 125110  35983  89884 118983  27436  85354\n 123984 114579 114646 123292  28012  87620  41105  64095  30044  95162\n  37565  29620  29573  90252  35805  65798 125271  29241  87949 124616\n  32311 128402  62221 114731  89860  50527  99721 114440  68766  56283\n  68532  28146  66608  89362 115475 114455  90379  76032 111322  56979]\n"
     ]
    }
   ],
   "source": [
    "print(\"200 Features with best Mutual Information score\")\n",
    "indices = np.argsort(nn_mutual_info)[-200:]\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "him however probably 1993 through between year give anything 20 little look 15 down made long etc read few must both doesn let thing without our own case someone things got better ll another using never point news believe 10 sure while years last question going said state might help mail system before find problem off take back cs still its since did computer work over usa something used really being too go right same after need ve please us thanks such want say many ca first two may where most those his here into world see because why much make very way anyone should even now these new use well am reply good could then had were he time their been also them people distribution does than think other get only up which we how when more who know your don just some like out will no me has so any do about would by one university all my what there they was an nntp com host at posting can as article or but if writes are not with be you have this on edu re that it for is and in of to the organization lines subject from \n"
     ]
    }
   ],
   "source": [
    "indices = np.argsort(nn_mutual_info)[-200:]\n",
    "str = \"\"\n",
    "for i in range(200):\n",
    "    str += vocabulary[indices[i]] + \" \"\n",
    "print(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_news_group_train_X = news_group_train_X[:, indices]\n",
    "reduced_news_group_test_X = news_group_test_X[:, indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.9 s, sys: 28.1 s, total: 42.9 s\nWall time: 31 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "nn_clf = LogisticRegression(penalty='l2', n_jobs=-1, solver='sag')\n",
    "nn_clf.fit(reduced_news_group_train_X, news_group_train_y.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy score:  0.362471274527\nTest Accuracy score:  0.29580456718\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Accuracy score: \", nn_clf.score(reduced_news_group_train_X, news_group_train_y))\n",
    "print(\"Test Accuracy score: \", nn_clf.score(reduced_news_group_test_X, news_group_test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L1 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non zeros coefficients:  (5887,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non zeros coefficients:  (5046,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non zeros coefficients:  (1378,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non zeros coefficients:  (67,)\n"
     ]
    }
   ],
   "source": [
    "# Coarse Parameter Search\n",
    "Cs = [10, 5, 1, 0.1]\n",
    "for c in Cs:\n",
    "    nn_clf = LogisticRegression(penalty='l1', C=c)\n",
    "    nn_clf.fit(news_group_train_X, news_group_train_y)\n",
    "    non_zero_coef = nn_clf.coef_[nn_clf.coef_ > 0.0].shape\n",
    "    print(\"Non zeros coefficients: \", non_zero_coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non zeros coefficients:  (1116,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non zeros coefficients:  (798,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non zeros coefficients:  (476,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non zeros coefficients:  (198,)\n"
     ]
    }
   ],
   "source": [
    "# Fine parameter search between 1 and 0.1\n",
    "\n",
    "Cs = [0.8, 0.6, 0.4, 0.2]\n",
    "for c in Cs:\n",
    "    nn_clf = LogisticRegression(penalty='l1', C=c)\n",
    "    nn_clf.fit(news_group_train_X, news_group_train_y)\n",
    "    non_zero_coef = nn_clf.coef_[nn_clf.coef_ > 0.0].shape\n",
    "    print(\"Non zeros coefficients: \", non_zero_coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non zeros coefficients:  (259,)\n"
     ]
    }
   ],
   "source": [
    "nn_clf = LogisticRegression(penalty='l1', C=0.25)\n",
    "nn_clf.fit(news_group_train_X, news_group_train_y)\n",
    "non_zero_coef = nn_clf.coef_[nn_clf.coef_ > 0.0].shape\n",
    "print(\"Non zeros coefficients: \", non_zero_coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     0,  12661,  14058,  27237,  27576,  27929,  28856,  29401,\n        29403,  30090,  30101,  30105,  30128,  30336,  30827,  31657,\n        31767,  31954,  32046,  32754,  33199,  33301,  33306,  33457,\n        34046,  34048,  34110,  34726,  34842,  35477,  35760,  37037,\n        37219,  37442,  37598,  37780,  37820,  37955,  38662,  39415,\n        39583,  39596,  39601,  39603,  39705,  39924,  40422,  40446,\n        41105,  42390,  42514,  42817,  43230,  43969,  44067,  44222,\n        46777,  46846,  47246,  47664,  47721,  48395,  48421,  48665,\n        49047,  49055,  49057,  49122,  49463,  49717,  50527,  50868,\n        51051,  51591,  51730,  54240,  54590,  55006,  55307,  55328,\n        55489,  56010,  56283,  56420,  56466,  58063,  58245,  58306,\n        58487,  58776,  59351,  59590,  59626,  59833,  59910,  60150,\n        60492,  60724,  60892,  60915,  62410,  62466,  62661,  62688,\n        62784,  63365,  63638,  65577,  65675,  66012,  66208,  66221,\n        68532,  68617,  68620,  68692,  68693,  69411,  69448,  69907,\n        69935,  71678,  72154,  72325,  73413,  74753,  74917,  74944,\n        74953,  75018,  76249,  78586,  79253,  79831,  80809,  80816,\n        82105,  82550,  83279,  83517,  83616,  83638,  83685,  83858,\n        83865,  83898,  83955,  84462,  86099,  87121,  88206,  88327,\n        89005,  89362,  89396,  89550,  89612,  90278,  91711,  92305,\n        92544,  92893,  93241,  93400,  93536,  93582,  94021,  94037,\n        94048,  94323,  94329,  94342,  94738,  94862,  95030,  95246,\n        95258,  95264,  95759,  98213,  98990,  99016,  99234,  99267,\n       101944, 101947, 101960, 102111, 103528, 103588, 104409, 104576,\n       105252, 105492, 105620, 105696, 106184, 106243, 106682, 106869])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_indices = np.unique(np.argwhere(nn_clf.coef_ > 0.0)[:, 1])[:200]\n",
    "feature_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_news_group_train_X = news_group_train_X[:, indices]\n",
    "reduced_news_group_test_X = news_group_test_X[:, indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.5 s, sys: 26.5 s, total: 41 s\nWall time: 29.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "nn_clf = LogisticRegression(penalty='l2', n_jobs=-1, solver='sag')\n",
    "nn_clf.fit(reduced_news_group_train_X, news_group_train_y.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy score:  0.362382888457\nTest Accuracy score:  0.29580456718\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Accuracy score: \", nn_clf.score(reduced_news_group_train_X, news_group_train_y))\n",
    "print(\"Test Accuracy score: \", nn_clf.score(reduced_news_group_test_X, news_group_test_y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
